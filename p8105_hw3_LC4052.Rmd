---
title: "p8105_hw3_LC4052"
output: github_document
Author: "Linqi Chu"
date: "2025-10-06"
---

```{r}
library(tidyverse)
library(ggridges)
library(patchwork)
library(dplyr)
library(ggplot2)
```


# Problem 1

## Import data

```{r}
library(p8105.datasets)
data("instacart")
```

## Description of variables

The dataset includes`r nrow(instacart)` observations and `r ncol(instacart)` variables, including `r names(instacart)`.

There are `r n_distinct(instacart$product_id)` distinct product ids and `r n_distinct(instacart$product_name)` product names. Departments contain `r unique(instacart$department)`.

## Number of aisles

```{r}
instacart |>
  count(aisle) |>
  arrange(desc(n)) |>
  slice(1) |>
  pull(aisle)

```
There are `r n_distinct(instacart$aisle` aisles. "fresh vegetables" are the most items ordered from.

## Plot of the number of items ordered in each aisle

```{r}
instacart |>
  count(aisle) |>
  filter(n > 10000) |>
  ggplot(aes(x = reorder(aisle, n), y = n)) +
  geom_col(fill = "steelblue", alpha = 0.8) +
  coord_flip() +
  labs(
    title = "Number of Items Ordered in Each Aisle",
    subtitle = "Aisles with more than 10,000 items ordered",
    x = "Aisle",
    y = "Number of Items Ordered"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::comma)

```

## Table of the three most popular items

```{r}
instacart |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle, product_name) |>
  summarise(order_count = n()) |>
  group_by(aisle) |>
  slice_max(order_count, n = 3) |>
  arrange(aisle, desc(order_count))
 
```

## Table of the mean hour

```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  mutate(
    day_of_week = factor(order_dow,
                       levels = 0:6,
                       labels = c("Sunday", "Monday", "Tuesday", "Wednesday",
                                  "Thursday", "Friday", "Saturday")),
    hour_of_day = order_hour_of_day
  ) |>
  group_by(product_name, day_of_week) |>
  summarize(mean_hour = round(mean(hour_of_day), 1)) |>
  pivot_wider(
    names_from = day_of_week,
    values_from = mean_hour
  )

```


# Problem 2

## Import and clean data

```{r}
# Import data
zipcodes_df = 
  read_csv("./zillow_data/Zip Codes.csv",
             na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  select(county,zip_code, everything())


# Clean the zip_codes file
zipcodes_df = 
  read_csv("./zillow_data/Zip Codes.csv",
             na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  select(county,zip_code, everything(), -file_date)

names(zipcodes_df)


# Clean the zip_zori file
zori_df = 
  read_csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
             na = c("NA", ".", "")) |>
  pivot_longer(
    cols = 10 : 125,
    names_to = "file_date", 
    values_to = "rent_price") |>
    mutate(file_date = as.character(file_date)) |>
  rename(county = CountyName, zip_code = RegionName) |>                       
  mutate(county = sub(" County$", "", county)) |> 
  arrange(zip_code) |>
  select(county,zip_code,file_date, rent_price, everything())


# Combine data
combined_data = 
  full_join(zipcodes_df, zori_df, by = c("county","zip_code")) |>
  select(county,zip_code,file_date, rent_price, neighborhood, everything())

names(combined_data)

```
## number of ZIP codes

```{r}
combined_data |>
  count(zip_code)|>
  filter(n == 116) |>
  nrow()

combined_data |>
  count(zip_code)|>
  filter(n < 10) |>
  nrow()

```
146 ZIP codes are observed 116 times.
171 ZIP codes are observed fewer than 10 times.


## Frequency differences of ZIP codes

```{r}
zip_freq =
  combined_data |>
  mutate(file_date = as.Date(file_date)) |>
  group_by(zip_code) |>
  summarize(
    n_months = n_distinct(format(file_date, "%Y-%m")),
    zip_count = n()
  )

ggplot(zip_freq, aes(x = n_months)) +
  geom_histogram(binwidth = 3, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of ZIP Code Observation Frequency",
    x = "Number of Months Observed",
    y = "Count of ZIP Codes"
  )
```

High-frequency ZIP codes might benefit from dense populations that generate continuous rental market activity throughout the data collection period. They may be also due to better technological coverage and more reliable reporting mechanisms.


## Table showing the average rental price in each borough and year

```{r}
borough_rent =
  combined_data |>
  mutate(
    file_date = as.Date(file_date),
    year = year(file_date)
  ) |>
  group_by(county, year) |>
  summarize(
    zip_count = n(),
    avg_rent = mean(rent_price, na.rm = TRUE)
  ) |>
  arrange(county, year)

borough_rent
```
The average rent of each borough increased with years. The rent in Manhattan borough remained relatively high. Zip code counts on 2024 were less than the ones on other years.


## Plot showing NYC Rental Prices within ZIP codes for all available years

```{r}
nyc_rent =
  combined_data |>
  mutate(
    file_date = as.Date(file_date),
    year = year(file_date)
  ) |>
  filter(!is.na(county) & !is.na(rent_price)) |>
  group_by(county, year) |>
  summarize(
    avg_rent = mean(rent_price, na.rm = TRUE),
    n_zip_codes = n_distinct(zip_code)
  ) |>
  ggplot(aes(x = year, y = avg_rent, color = county)) +
  geom_line(size = 1.2, alpha = 0.8) +
  geom_point(size = 2.5) +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed", size = 0.5, alpha = 0.5) +
  labs(
    title = "NYC Rental Price Trends by Borough (All Available Years)",
    subtitle = "Average rent prices across ZIP codes with trend lines",
    x = "Year",
    y = "Average Rent ($)",
    color = "Borough"
  ) +
  theme_minimal() +
  scale_x_continuous() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

print(nyc_rent)

```
The plot reveals that all five boroughs have experienced rental price increases over the eight-year window. The rent prices in Manhattan maintained higher than other areas throughout the entire period, while the ones in Bronx remained the lowest.

The COVID-19 pandemic period (2020-2021) represents a disruption to established trends, with all boroughs experiencing either rental price declines or significant growth deceleration. Manhattan appears to have been most affected.


## Plot showing the distribution of ZIP-code-level rental prices across boroughs

```{r}
rent_2023 =
  combined_data |>
  mutate(
    file_date = as.Date(file_date),
    year = lubridate::year(file_date),
    month = lubridate::month(file_date, label = TRUE)
  ) |>
  filter(year == 2023) |>
  group_by(zip_code, county, month) |>
  summarize(
    avg_rent = mean(rent_price, na.rm = TRUE)
  )

borough_comparison_plot =
  rent_2023 |>
  ggplot(aes(x = county, y = avg_rent, fill = county)) +
  geom_violin(alpha = 0.7, trim = FALSE) +
  geom_boxplot(width = 0.2, alpha = 0.8, outlier.shape = NA) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 3, color = "red") +
  labs(
    title = "Distribution of Average Rental Prices by Borough (2023)",
    subtitle = "Violin plots show density distribution, boxplots show quartiles, red diamonds indicate means",
    x = "Borough",
    y = "Average Monthly Rent ($)",
    fill = "Borough"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::dollar) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, color = "gray50", size = 10),
    axis.text.x = element_text(angle = 0, hjust = 0.5),
    panel.grid.major.x = element_blank()
  ) +
  coord_flip()

print(borough_comparison_plot)
```


## Combine the two plots and export it

```{r}
combined_plot = nyc_rent / borough_comparison_plot
combined_plot


ggsave("./results/combined_plot.png", 
       plot = combined_plot,
       width = 16,
       height = 8,
       dpi = 300)
```




# Problem 3

```{r}








```


```{r}









```










