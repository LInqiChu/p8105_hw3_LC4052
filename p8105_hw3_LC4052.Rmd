---
title: "p8105_hw3_LC4052"
output: github_document
Author: "Linqi Chu"
date: "2025-10-06"
---

```{r}
library(tidyverse)
library(ggridges)
library(patchwork)
library(dplyr)
library(ggplot2)
```


# Problem 1

## Import data

```{r}
library(p8105.datasets)
data("instacart")
```

## Description of variables

The dataset includes`r nrow(instacart)` observations and `r ncol(instacart)` variables, including `r names(instacart)`.

There are `r n_distinct(instacart$product_id)` distinct product ids and `r n_distinct(instacart$product_name)` product names. Departments contain `r unique(instacart$department)`.

## Number of aisles

```{r}
instacart |>
  count(aisle) |>
  arrange(desc(n)) |>
  slice(1) |>
  pull(aisle)

```
There are `r n_distinct(instacart$aisle` aisles. "fresh vegetables" are the most items ordered from.

## Plot of the number of items ordered in each aisle

```{r}
instacart |>
  count(aisle) |>
  filter(n > 10000) |>
  ggplot(aes(x = reorder(aisle, n), y = n)) +
  geom_col(fill = "steelblue", alpha = 0.8) +
  coord_flip() +
  labs(
    title = "Number of Items Ordered in Each Aisle",
    subtitle = "Aisles with more than 10,000 items ordered",
    x = "Aisle",
    y = "Number of Items Ordered"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::comma)

```

## Table of the three most popular items

```{r}
instacart |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle, product_name) |>
  summarise(order_count = n()) |>
  group_by(aisle) |>
  slice_max(order_count, n = 3) |>
  arrange(aisle, desc(order_count))
 
```

## Table of the mean hour

```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  mutate(
    day_of_week = factor(order_dow,
                       levels = 0:6,
                       labels = c("Sunday", "Monday", "Tuesday", "Wednesday",
                                  "Thursday", "Friday", "Saturday")),
    hour_of_day = order_hour_of_day
  ) |>
  group_by(product_name, day_of_week) |>
  summarize(mean_hour = round(mean(hour_of_day), 1)) |>
  pivot_wider(
    names_from = day_of_week,
    values_from = mean_hour
  )

```




# Problem 2

## Import and clean data

```{r}
# Import data
zipcodes_df = 
  read_csv("./zillow_data/Zip Codes.csv",
             na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  select(county,zip_code, everything())


# Clean the zip_codes file
zipcodes_df = 
  read_csv("./zillow_data/Zip Codes.csv",
             na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  select(county,zip_code, everything(), -file_date)

names(zipcodes_df)


# Clean the zip_zori file
zori_df = 
  read_csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
             na = c("NA", ".", "")) |>
  pivot_longer(
    cols = 10 : 125,
    names_to = "file_date", 
    values_to = "rent_price") |>
    mutate(file_date = as.character(file_date)) |>
  rename(county = CountyName, zip_code = RegionName) |>                       
  mutate(county = sub(" County$", "", county)) |> 
  arrange(zip_code) |>
  select(county,zip_code,file_date, rent_price, everything())


# Combine data
combined_data = 
  full_join(zipcodes_df, zori_df, by = c("county","zip_code")) |>
  select(county,zip_code,file_date, rent_price, neighborhood, everything())

names(combined_data)

```
## number of ZIP codes

```{r}
combined_data |>
  count(zip_code)|>
  filter(n == 116) |>
  nrow()

combined_data |>
  count(zip_code)|>
  filter(n < 10) |>
  nrow()

```
146 ZIP codes are observed 116 times.
171 ZIP codes are observed fewer than 10 times.


## Frequency differences of ZIP codes

```{r}
zip_freq =
  combined_data |>
  mutate(file_date = as.Date(file_date)) |>
  group_by(zip_code) |>
  summarize(
    n_months = n_distinct(format(file_date, "%Y-%m")),
    zip_count = n()
  )

ggplot(zip_freq, aes(x = n_months)) +
  geom_histogram(binwidth = 3, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of ZIP Code Observation Frequency",
    x = "Number of Months Observed",
    y = "Count of ZIP Codes"
  )
```

High-frequency ZIP codes might benefit from dense populations that generate continuous rental market activity throughout the data collection period. They may be also due to better technological coverage and more reliable reporting mechanisms.


## Table showing the average rental price in each borough and year

```{r}
borough_rent =
  combined_data |>
  mutate(
    file_date = as.Date(file_date),
    year = year(file_date)
  ) |>
  group_by(county, year) |>
  summarize(
    zip_count = n(),
    avg_rent = mean(rent_price, na.rm = TRUE)
  ) |>
  arrange(county, year)

borough_rent
```
The average rent of each borough increased with years. The rent in Manhattan borough remained relatively high. Zip code counts on 2024 were less than the ones on other years.


## Plot showing NYC Rental Prices within ZIP codes for all available years

```{r}
nyc_rent =
  combined_data |>
  mutate(
    file_date = as.Date(file_date),
    year = year(file_date)
  ) |>
  filter(!is.na(county) & !is.na(rent_price)) |>
  group_by(county, year) |>
  summarize(
    avg_rent = mean(rent_price, na.rm = TRUE),
    n_zip_codes = n_distinct(zip_code)
  ) |>
  ggplot(aes(x = year, y = avg_rent, color = county)) +
  geom_line(size = 1.2, alpha = 0.8) +
  geom_point(size = 2.5) +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed", size = 0.5, alpha = 0.5) +
  labs(
    title = "NYC Rental Price Trends by Borough (All Available Years)",
    subtitle = "Average rent prices across ZIP codes with trend lines",
    x = "Year",
    y = "Average Rent ($)",
    color = "Borough"
  ) +
  theme_minimal() +
  scale_x_continuous() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

print(nyc_rent)

```
The plot reveals that all five boroughs have experienced rental price increases over the eight-year window. The rent prices in Manhattan maintained higher than other areas throughout the entire period, while the ones in Bronx remained the lowest.

The COVID-19 pandemic period (2020-2021) represents a disruption to established trends, with all boroughs experiencing either rental price declines or significant growth deceleration. Manhattan appears to have been most affected.


## Plot showing the distribution of ZIP-code-level rental prices across boroughs

```{r}
rent_2023 =
  combined_data |>
  mutate(
    file_date = as.Date(file_date),
    year = lubridate::year(file_date),
    month = lubridate::month(file_date, label = TRUE)
  ) |>
  filter(year == 2023) |>
  group_by(zip_code, county, month) |>
  summarize(
    avg_rent = mean(rent_price, na.rm = TRUE)
  )

borough_comparison_plot =
  rent_2023 |>
  ggplot(aes(x = county, y = avg_rent, fill = county)) +
  geom_violin(alpha = 0.7, trim = FALSE) +
  geom_boxplot(width = 0.2, alpha = 0.8, outlier.shape = NA) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 3, color = "red") +
  labs(
    title = "Distribution of Average Rental Prices by Borough (2023)",
    subtitle = "Violin plots show density distribution, boxplots show quartiles, red diamonds indicate means",
    x = "Borough",
    y = "Average Monthly Rent ($)",
    fill = "Borough"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::dollar) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, color = "gray50", size = 10),
    axis.text.x = element_text(angle = 0, hjust = 0.5),
    panel.grid.major.x = element_blank()
  ) +
  coord_flip()

print(borough_comparison_plot)
```


## Combine the two plots and export it

```{r}
combined_plot = nyc_rent / borough_comparison_plot
combined_plot


ggsave("./results/combined_plot.png", 
       plot = combined_plot,
       width = 16,
       height = 8,
       dpi = 300)
```




# Problem 3

## Import and clean the data

```{r}
# Tidy each dataset
nhanes_accel = 
  read_csv("./accelerometer_data/nhanes_accel.csv",
             na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  pivot_longer(
    cols = starts_with("min"),
    names_to = "minute",
    values_to = "MIMS"
  ) |>
  mutate(
    minute = as.numeric(str_remove(minute, "min")),
    time_of_day = minute - 1,
    hour = floor(time_of_day / 60),
    minute_of_hour = time_of_day %% 60
  ) |>
 arrange(seqn, minute)

nhanes_covar = 
  read_csv("./accelerometer_data/nhanes_covar.csv",
             na = c("NA", ".", ""),
            skip = 4) |>
  janitor::clean_names()

# Combine two datasets
combined_MIMC = nhanes_accel |>
  left_join(nhanes_covar, by = "seqn") |>
  filter(age >= 21) |>
  filter(!is.na(sex), !is.na(age), !is.na(bmi), !is.na(education)) |>
  mutate(
    sex = factor(sex, 
                 levels = c(1, 2), 
                 labels = c("Male", "Female")),
    education = factor(education, 
                      levels = c(1, 2, 3), 
                      labels = c("Less than high school", 
                                "High school equivalent", 
                                "More than high school"),
                      ordered = TRUE),
    age = as.numeric(age),
    bmi = as.numeric(bmi),
    
    # 参与者ID转换为因子
    seqn = as.factor(seqn)
  )

```

```{r}
education_table <- combined_data |>
  distinct(seqn, .keep_all = TRUE) |>  # 每个参与者只保留一行
  group_by(education, sex) |>
  summarise(count = n(), .groups = "drop") |>
  pivot_wider(
    names_from = sex,
    values_from = count,
    values_fill = 0
  ) |>
  mutate(Total = Male + Female) |>
  arrange(education)

age_distribution_plot <- combined_data |>
  distinct(seqn, .keep_all = TRUE) |>  # 每个参与者只保留一行
  ggplot(aes(x = age, fill = sex)) +
  geom_histogram(position = "dodge", bins = 20, alpha = 0.7) +
  facet_wrap(~education, ncol = 1) +
  scale_fill_manual(values = c("Male" = "#3498db", "Female" = "#e74c3c")) +
  labs(
    title = "Age Distribution by Sex and Education Level",
    x = "Age (years)",
    y = "Count",
    fill = "Sex"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "bottom",
    strip.text = element_text(face = "bold")
  )



```
Produce a reader-friendly table for the number of men and women in each education category, and create a visualization of the age distributions for men and women in each education category. Comment on these items.







```{r}
total_activity <- combined_data |>
  group_by(seqn, sex, age, bmi, education) |>
  summarise(
    total_activity = sum(MIMS, na.rm = TRUE),
    .groups = "drop"
  )

# 查看总活动量的摘要统计
summary(total_activity$total_activity)

# 2. 创建总活动量 vs 年龄的可视化
activity_age_plot <- total_activity |>
  ggplot(aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = 0.6, size = 2) +
  geom_smooth(method = "loess", se = TRUE, linewidth = 1) +
  facet_wrap(~education, ncol = 1) +
  scale_color_manual(values = c("Male" = "#3498db", "Female" = "#e74c3c")) +
  labs(
    title = "Total Daily Activity by Age, Sex, and Education Level",
    x = "Age (years)",
    y = "Total Activity (MIMS)",
    color = "Sex"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "bottom",
    strip.text = element_text(face = "bold", size = 11),
    panel.spacing = unit(1, "lines")
  )

print(activity_age_plot)

```

Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot.

```{r}






```




Accelerometer data allows the inspection activity over the course of the day. Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences

```{r}
# 1. 计算每个教育水平、性别和时间点的平均活动量
hourly_activity <- combined_data |>
  group_by(education, sex, hour, minute_of_hour) |>
  summarise(
    mean_MIMS = mean(MIMS, na.rm = TRUE),
    .groups = "drop"
  ) |>
  mutate(
    time_in_hours = hour + minute_of_hour / 60  # 将时间转换为小时的小数形式
  )

# 2. 创建24小时活动时间过程图
activity_timecourse_plot <- hourly_activity |>
  ggplot(aes(x = time_in_hours, y = mean_MIMS, color = sex)) +
  geom_line(linewidth = 0.8, alpha = 0.7) +
  geom_smooth(se = TRUE, linewidth = 1.2) +
  facet_wrap(~education, ncol = 1) +
  scale_color_manual(values = c("Male" = "#3498db", "Female" = "#e74c3c")) +
  scale_x_continuous(
    breaks = seq(0, 24, 4),
    labels = c("0:00", "4:00", "8:00", "12:00", "16:00", "20:00", "24:00")
  ) +
  labs(
    title = "24-Hour Activity Time Course by Education Level and Sex",
    x = "Time of Day",
    y = "Average Activity (MIMS)",
    color = "Sex"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "bottom",
    strip.text = element_text(face = "bold", size = 11),
    panel.spacing = unit(1, "lines"),
    panel.grid.minor = element_blank()
  )

print(activity_timecourse_plot)






```







